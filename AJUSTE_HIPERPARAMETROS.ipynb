{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dba4c38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import de librerías necesarias\n",
    "import pyreadr\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Cursor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, date\n",
    "from sklearn import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2\n",
    "from scipy.stats import chi2_contingency\n",
    "import scipy.stats as stats\n",
    "from sklearn.metrics import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.stats import mannwhitneyu\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from collections import defaultdict\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor \n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn import linear_model\n",
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from patsy import cr\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost as xgb\n",
    "import cupy as cp\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67dbc7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.int = np.int32\n",
    "np.float = np.float64\n",
    "np.bool = np.bool_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51e68ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar los datos de R a Python\n",
    "datos = pyreadr.read_r('area_desbalance_ionico.RData')\n",
    "\n",
    "#Para comprobar que se importan correctamente los datos\n",
    "#print(datos.keys())\n",
    "\n",
    "#Este archivo tiene tres variables\n",
    "\n",
    "#datos_anon_D: datos extraídos de los ECGS - edad, sexo, fecha, hora y \n",
    "#nombre del fichero. Hay un código (código) que identifica a cada paciente\n",
    "datos_anon_DF = datos['datos_anon_DF']\n",
    "\n",
    "#lead_anon_DF\n",
    "#variables electrocardiográficas correspondiente a los ECGs de la variable anterior\n",
    "leads_anon_DF = datos['leads_anon_DF']\n",
    "\n",
    "#pacs_con_ECGs_DF\n",
    "#variables de los datos del potasio, fecha de la analítica, edad del paciente, sexo\n",
    "#nivel de K y código del paciente\n",
    "pacs_con_ECGs_DF = datos['pacs_con_ECGs_DF']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dde6a01",
   "metadata": {},
   "source": [
    "# Normalidad - Hiperpotasemia - Hipopotasemia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "190d4314",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primer paso: coger solo los valores de K normales y de hiperpotasemia\n",
    "k_val = pacs_con_ECGs_DF.copy()\n",
    "\n",
    "limites = [float('-inf'), 3.5, 5.2, float('inf')]\n",
    "etiquetas = [1, 0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a819240",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_valores = k_val.copy()\n",
    "\n",
    "k_valores['categoria'] = pd.cut(k_valores['K'], bins=limites, labels=etiquetas, right=False)\n",
    "\n",
    "#Se reemplazan los sexos por enteros\n",
    "#1: Hombre\n",
    "#0: Mujer\n",
    "k_valores['Sexo'] = k_valores['Sexo'].replace({'M': 1, 'F': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb192f44",
   "metadata": {},
   "source": [
    "# Eliminación de variables con datos vacíos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5059f3d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#En leads_anon_DF, se van a eliminar aquellas columnas en las que falte más del 1% de los datos\n",
    "\n",
    "#El como máximo (el 100%) de datos que podría tener cada característica, sería igual al número total de filas que\n",
    "#hay registradas\n",
    "#Se calcula el 10% y se redondea sin decimales\n",
    "diez_pct_datos = round(len(leads_anon_DF) * 0.01, 0)\n",
    "\n",
    "#Ahora, se va a coger un subconjunto del dataframe en el que se eliminan las\n",
    "#características cuyo número de datos sea menor al 10%\n",
    "\n",
    "#Se cuenta el número de NaN o celdas sin datos en cada columna\n",
    "celdas_sin_datos = leads_anon_DF.isnull().sum()\n",
    "\n",
    "#Se cogen las características cuyo número de datos vacíos es mayor o igual al 10%\n",
    "caracteristicas_eliminar = celdas_sin_datos[celdas_sin_datos >= diez_pct_datos].index\n",
    "\n",
    "#Se crear el subDataFrame eliminando las columnas correspondientes\n",
    "leads_anon_DF_limpio = leads_anon_DF.drop(columns = caracteristicas_eliminar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e82f7dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora hay que asociar a cada análisis de sangre, su ECG más cercano\n",
    "def ECG_mas_reciente(fecha, codigo):\n",
    "     \n",
    "    archivos_ECGs = datos_anon_DF.loc[(datos_anon_DF['codigo'] == codigo) & (datos_anon_DF['date'] >= (fecha - timedelta(days=5))) & (datos_anon_DF['date'] <= (fecha + timedelta(days=5)))]    \n",
    "    \n",
    "    fechas_archivos = archivos_ECGs['date']\n",
    "    horas_archivos = archivos_ECGs['time']\n",
    "        \n",
    "    diferencia_temporal = [abs(fecha - fecha_archivo) for fecha_archivo in fechas_archivos]\n",
    "    \n",
    "    ecg = (datos_anon_DF.index[(datos_anon_DF['codigo'] == codigo) & (datos_anon_DF['date'] >= (fecha - timedelta(days=5))) & (datos_anon_DF['date'] <= (fecha + timedelta(days=5)))]).tolist()\n",
    "    \n",
    "    if(len(diferencia_temporal) > 0):\n",
    "    \n",
    "        combinado = list(zip(diferencia_temporal, ecg))\n",
    "        combinado = sorted(combinado, key=lambda x: x[0])\n",
    "\n",
    "        diferencia_temporal, ecg = zip(*combinado)\n",
    "        \n",
    "    return ecg, diferencia_temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8fba01f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Ahora, se añade la columna \"Categoria\" y \"Sexo\" a leads_anon_DF_limpio\n",
    "#Se crean esas columnas en el nuevo dataframe con valores a Nan\n",
    "leads_anon_DF_limpio['Sexo'] = float('NaN')\n",
    "leads_anon_DF_limpio['categoria'] = float('NaN')\n",
    "leads_anon_DF_limpio['K'] = float('NaN')\n",
    "leads_anon_DF_limpio['Edad'] = float('NaN')\n",
    "ecgs_utilizadas = {} \n",
    "\n",
    "for i in range(len(k_valores)):\n",
    "    fecha_hora = (k_valores['Fecha'].iloc[i]).to_pydatetime()\n",
    "    fecha = fecha_hora.date()\n",
    "    \n",
    "    indice, dist_temporal = ECG_mas_reciente(fecha, k_valores['codigo'].iloc[i])\n",
    "  \n",
    "    for j in range(len(indice)):\n",
    "        #Si el ECGs no tiene una analítica asignada, se le pone\n",
    "        if indice[j] not in ecgs_utilizadas:\n",
    "            #Se actualizan los valores de las columnas \"Sexo\" y \"Categoría\"\n",
    "            #de la fila correspondiente\n",
    "            leads_anon_DF_limpio.at[indice[j], 'Sexo'] = k_valores['Sexo'].iloc[i]\n",
    "            leads_anon_DF_limpio.at[indice[j], 'Edad'] = k_valores['Edad'].iloc[i]\n",
    "            leads_anon_DF_limpio.at[indice[j], 'categoria'] = k_valores['categoria'].iloc[i]\n",
    "            leads_anon_DF_limpio.at[indice[j], 'K'] = k_valores['K'].iloc[i]\n",
    "\n",
    "            ecgs_utilizadas[indice[j]] = [k_valores['categoria'].iloc[i], dist_temporal[j].days]\n",
    "\n",
    "        #Si el ECG ya tiene una analítica asociada, si la nueva analítica tiene un valor\n",
    "        #de categoría diferente y se asocia con una anormalidad, se cambia\n",
    "        else:\n",
    "            if((dist_temporal[j].days < ecgs_utilizadas[indice[j]][1])):\n",
    "                leads_anon_DF_limpio.at[indice[j], 'categoria'] = k_valores['categoria'].iloc[i]\n",
    "                leads_anon_DF_limpio.at[indice[j], 'K'] = k_valores['K'].iloc[i]\n",
    "                ecgs_utilizadas[indice[j]][1] = dist_temporal[j].days\n",
    "                \n",
    "            if((dist_temporal[j].days == ecgs_utilizadas[indice[j]][1]) & (k_valores['categoria'].iloc[i] > ecgs_utilizadas[indice[j]][0])):\n",
    "                leads_anon_DF_limpio.at[indice[j], 'categoria'] = k_valores['categoria'].iloc[i]\n",
    "                leads_anon_DF_limpio.at[indice[j], 'K'] = k_valores['K'].iloc[i]\n",
    "                ecgs_utilizadas[indice[j]][1] = dist_temporal[j].days                \n",
    "            \n",
    "#Se eliminan las filas que tengan la variable objetivo \"categoria\" a NaN\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.dropna(subset=['categoria'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe778f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pparea = leads_anon_DF_limpio.filter(regex='_pparea', axis=1)\n",
    "tparea = leads_anon_DF_limpio.filter(regex='_tparea', axis=1)\n",
    "\n",
    "ppamp = leads_anon_DF_limpio.filter(regex='_ppamp', axis=1)\n",
    "rpamp = leads_anon_DF_limpio.filter(regex='_rpamp', axis=1)\n",
    "spamp = leads_anon_DF_limpio.filter(regex='_spamp', axis=1)\n",
    "tpamp = leads_anon_DF_limpio.filter(regex='_tpamp', axis=1)\n",
    "\n",
    "rpdur = leads_anon_DF_limpio.filter(regex='_rpdur', axis=1)\n",
    "spdur = leads_anon_DF_limpio.filter(regex='_spdur', axis=1)\n",
    "tpdur = leads_anon_DF_limpio.filter(regex='_tpdur', axis=1)\n",
    "\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=pparea.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=tparea.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=ppamp.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=rpamp.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=spamp.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=tpamp.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=rpdur.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=spdur.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=tpdur.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37df874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parea = leads_anon_DF_limpio.filter(regex='_parea', axis=1)\n",
    "pppparea = leads_anon_DF_limpio.filter(regex='_pppparea', axis=1)\n",
    "qdur = leads_anon_DF_limpio.filter(regex='_qdur', axis=1)\n",
    "sdur = leads_anon_DF_limpio.filter(regex='_sdur', axis=1)\n",
    "tarea = leads_anon_DF_limpio.filter(regex='_tarea', axis=1)\n",
    "tptparea = leads_anon_DF_limpio.filter(regex='(_tptparea$)', axis=1)\n",
    "tptpdur = leads_anon_DF_limpio.filter(regex='(_tptpdur$)', axis=1)\n",
    "st = leads_anon_DF_limpio.filter(regex='(_stend$|_st80$|_ston$)', axis=1)\n",
    "stslope = leads_anon_DF_limpio.filter(regex='(_stslope)', axis=1)\n",
    "stdur = leads_anon_DF_limpio.filter(regex='(_stdur$)', axis=1).drop(columns=['V2_stdur'])\n",
    "\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=parea.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=pppparea.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=qdur.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=sdur.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=tarea.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=tptparea.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=tptpdur.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=st.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=stslope.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=stdur.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14c21ff",
   "metadata": {},
   "source": [
    "# CARGA DE DATOS FINALIZADA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77eee81",
   "metadata": {},
   "source": [
    "### Hipopotasemia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ebbcec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = leads_anon_DF_limpio[leads_anon_DF_limpio['categoria'] != 2]\n",
    "y = x['categoria'].astype(int)\n",
    "\n",
    "x = x.drop(['K', 'categoria'], axis = 1)\n",
    "x = x.where(pd.notna(x), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cedbdb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_aic = ['aVL_pamp', 'II_ramp', 'V5_rdur', 'aVL_vat', 'V3_vat', 'aVL_qrsppk', 'V1_qrsppk', 'III_qrsdur', 'V1_qrsdur', 'V3_stmid', 'V6_stmid', 'V2_stdur', 'aVR_tamp', 'V1_tamp', 'V5_tamp', 'I_tdur', 'V6_tdur']\n",
    "cars_bor = ['aVL_pamp', 'V4_ramp', 'I_stmid', 'aVR_stmid', 'V2_stmid', 'V3_stmid', 'V2_stdur', 'aVR_tamp', 'V2_tamp', 'V3_tamp']\n",
    "\n",
    "caracteristicas = [cars_aic, cars_bor]\n",
    "modelos = ['AIC', 'Boruta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eceef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = IterativeImputer(max_iter=5, sample_posterior=True, initial_strategy='mean', skip_complete=True)\n",
    "\n",
    "x = pd.DataFrame(imputer.fit_transform(x), columns=x.columns)\n",
    "\n",
    "esc = StandardScaler()\n",
    "x = pd.DataFrame(esc.fit_transform(x), columns=x.columns)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b2a7f6",
   "metadata": {},
   "source": [
    "### Hiperpotasemia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7cb33c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = leads_anon_DF_limpio[leads_anon_DF_limpio['categoria'] != 1]\n",
    "y = x['categoria'].astype(int)\n",
    "y = y.apply(lambda x: 1 if x == 2 else 0)\n",
    "\n",
    "x = x.drop(['K', 'categoria'], axis = 1)\n",
    "x = x.where(pd.notna(x), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4b0eb366",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_aic = ['V5_qamp', 'I_rdur', 'V5_samp', 'V5_vat', 'V1_qrsdur', 'aVL_qrsarea', 'V1_qrsarea', 'V3_qrsarea', 'V3_stmid', 'V2_tamp', 'V6_qtint']\n",
    "cars_bor = ['I_ramp', 'V5_samp', 'I_qrsppk', 'II_qrsppk', 'aVR_qrsppk', 'V1_qrsppk', 'V3_qrsppk', 'V4_qrsppk', 'V5_qrsppk', 'V1_qrsdur', 'V5_qrsarea', 'V4_stmid', 'V2_tamp', 'V3_tamp', 'aVL_tdur', 'III_qtint', 'V6_qtint', 'Edad']\n",
    "caracteristicas = [cars_aic, cars_bor]\n",
    "modelos = ['AIC', 'Boruta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198fe8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = IterativeImputer(max_iter=5, sample_posterior=True, initial_strategy='mean', skip_complete=True)\n",
    "\n",
    "x = pd.DataFrame(imputer.fit_transform(x), columns=x.columns)\n",
    "\n",
    "esc = StandardScaler()\n",
    "x = pd.DataFrame(esc.fit_transform(x), columns=x.columns)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fa9ffc",
   "metadata": {},
   "source": [
    "### Regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a2e85e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = leads_anon_DF_limpio\n",
    "x = x.sample(frac=1, random_state=1)\n",
    "y = x['K']\n",
    "\n",
    "x = x.drop(['K', 'categoria'], axis = 1)\n",
    "x = x.where(pd.notna(x), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "381fc7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_aic = ['I_rdur', 'I_qrsarea', 'V1_qrsarea', 'V2_stdur', 'V2_tamp', 'V6_qtint']\n",
    "cars_boruta = ['V1_pamp', 'II_ramp', 'V5_samp', 'III_vat', 'V1_vat', 'I_qrsppk', 'aVF_qrsppk', 'V1_qrsppk', 'V4_qrsppk', 'V2_qrsarea', 'I_stmid', 'V3_stmid', 'aVR_tamp', 'V1_tamp', 'V2_tamp', 'V3_tamp', 'I_tdur', 'aVL_tdur', 'V6_tdur', 'Edad']\n",
    "\n",
    "caracteristicas = [cars_aic, cars_bor]\n",
    "modelos = ['AIC', 'Boruta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f953ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = IterativeImputer(max_iter=5, sample_posterior=True, initial_strategy='mean', skip_complete=True)\n",
    "\n",
    "x = pd.DataFrame(imputer.fit_transform(x), columns=x.columns)\n",
    "\n",
    "esc = StandardScaler()\n",
    "x = pd.DataFrame(esc.fit_transform(x), columns=x.columns)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e859d6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d9dd0f",
   "metadata": {},
   "source": [
    "# CARTs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749d4782",
   "metadata": {},
   "source": [
    "### Hipopotasemia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "715e45f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      " \n",
      "Mejores parámetros AIC: {'max_depth': 10, 'max_features': 10, 'max_leaf_nodes': 10}\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      " \n",
      "Mejores parámetros Boruta: {'max_depth': None, 'max_features': 5, 'max_leaf_nodes': 10}\n"
     ]
    }
   ],
   "source": [
    "parametros = {\n",
    "    'max_depth': [None, 10, 25, 50, 100],\n",
    "    'max_features': [1, 5, 10, None], \n",
    "    'max_leaf_nodes': [None, 5, 10, 25, 50]\n",
    "    \n",
    "}\n",
    "\n",
    "ad = DecisionTreeClassifier(class_weight='balanced')\n",
    "\n",
    "for i in range(len(caracteristicas)):\n",
    "    x2 = x[caracteristicas[i]]\n",
    "\n",
    "    grid = GridSearchCV(ad, parametros, cv=skf, scoring='roc_auc', n_jobs=-1, verbose=2)\n",
    "\n",
    "    grid.fit(x2, y)\n",
    "\n",
    "    print(f' ')\n",
    "    print(f\"Mejores parámetros {modelos[i]}: {grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57333c32",
   "metadata": {},
   "source": [
    "### Hiperpotasemia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b18e116f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      " \n",
      "Mejores parámetros AIC: {'max_depth': None, 'max_features': 10, 'max_leaf_nodes': 50}\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      " \n",
      "Mejores parámetros Boruta: {'max_depth': 100, 'max_features': 10, 'max_leaf_nodes': 50}\n"
     ]
    }
   ],
   "source": [
    "parametros = {\n",
    "    'max_depth': [None, 10, 25, 50, 100],\n",
    "    'max_features': [1, 5, 10, None], \n",
    "    'max_leaf_nodes': [None, 5, 10, 25, 50]\n",
    "    \n",
    "}\n",
    "\n",
    "ad = DecisionTreeClassifier(class_weight='balanced')\n",
    "\n",
    "for i in range(len(caracteristicas)):\n",
    "    x2 = x[caracteristicas[i]]\n",
    "\n",
    "    grid = GridSearchCV(ad, parametros, cv=skf, scoring='roc_auc', n_jobs=-1, verbose=2)\n",
    "\n",
    "    grid.fit(x2, y)\n",
    "\n",
    "    print(f' ')\n",
    "    print(f\"Mejores parámetros {modelos[i]}: {grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326a8d5b",
   "metadata": {},
   "source": [
    "### Regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dbb43324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros AIC: {'max_depth': 100, 'max_features': 1, 'max_leaf_nodes': 5}\n",
      "Mejores parámetros Boruta: {'max_depth': 100, 'max_features': 10, 'max_leaf_nodes': 5}\n"
     ]
    }
   ],
   "source": [
    "parametros = {\n",
    "    'max_depth': [None, 10, 25, 50, 100],\n",
    "    'max_features': [1, 5, 10, None], \n",
    "    'max_leaf_nodes': [None, 5, 10, 25, 50]\n",
    "    \n",
    "}\n",
    "\n",
    "ad = DecisionTreeRegressor(criterion='squared_error')\n",
    "\n",
    "for i in range(len(caracteristicas)):\n",
    "    x2 = x[caracteristicas[i]]\n",
    "\n",
    "    grid = GridSearchCV(ad, parametros, cv=5, scoring='r2', n_jobs=-1)\n",
    "\n",
    "    grid.fit(x2, y)\n",
    "\n",
    "    print(f\"Mejores parámetros {modelos[i]}: {grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f89ad9",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405976cf",
   "metadata": {},
   "source": [
    "### Hipopotasemia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "466b0dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros AIC: {'n_estimators': 150, 'max_leaf_nodes': None, 'max_features': None, 'max_depth': 25}\n",
      "Mejores parámetros Boruta: {'n_estimators': 150, 'max_leaf_nodes': None, 'max_features': None, 'max_depth': None}\n"
     ]
    }
   ],
   "source": [
    "parametros = {\n",
    "    'n_estimators': [100, 150, 200, 250],\n",
    "    'max_depth': [None, 10, 25, 50, 100],\n",
    "    'max_features': [5, 10, None], \n",
    "    'max_leaf_nodes': [None, 5, 10, 25, 50]\n",
    "}\n",
    "\n",
    "ad = RandomForestClassifier(n_jobs=-1, oob_score=roc_auc_score, class_weight='balanced')\n",
    "\n",
    "for i in range(len(caracteristicas)):\n",
    "    x2 = x[caracteristicas[i]]\n",
    "\n",
    "    grid = RandomizedSearchCV(ad, parametros, n_iter=100, cv=skf, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "    grid.fit(x2, y)\n",
    "\n",
    "    print(f\"Mejores parámetros {modelos[i]}: {grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f15a67",
   "metadata": {},
   "source": [
    "### Hiperpotasemia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "910b8767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros AIC: {'n_estimators': 200, 'max_leaf_nodes': None, 'max_features': None, 'max_depth': 100}\n",
      "Mejores parámetros Boruta: {'n_estimators': 200, 'max_leaf_nodes': None, 'max_features': 5, 'max_depth': None}\n"
     ]
    }
   ],
   "source": [
    "parametros = {\n",
    "    'n_estimators': [100, 150, 200, 250],\n",
    "    'max_depth': [None, 10, 25, 50, 100],\n",
    "    'max_features': [5, 10, None], \n",
    "    'max_leaf_nodes': [None, 5, 10, 25, 50]\n",
    "}\n",
    "\n",
    "ad = RandomForestClassifier(n_jobs=-1, oob_score=roc_auc_score, class_weight='balanced')\n",
    "\n",
    "for i in range(len(caracteristicas)):\n",
    "    x2 = x[caracteristicas[i]]\n",
    "\n",
    "    grid = RandomizedSearchCV(ad, parametros, n_iter=100, cv=skf, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "    grid.fit(x2, y)\n",
    "\n",
    "    print(f\"Mejores parámetros {modelos[i]}: {grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478cac9e",
   "metadata": {},
   "source": [
    "### Regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "29f6a3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros AIC: {'n_estimators': 250, 'max_leaf_nodes': None, 'max_features': 5, 'max_depth': None}\n",
      "Mejores parámetros Boruta: {'n_estimators': 200, 'max_leaf_nodes': None, 'max_features': 10, 'max_depth': None}\n"
     ]
    }
   ],
   "source": [
    "parametros = {\n",
    "    'n_estimators': [100, 150, 200, 250],\n",
    "    'max_depth': [None, 10, 25, 50, 100],\n",
    "    'max_features': [5, 10, None], \n",
    "    'max_leaf_nodes': [None, 5, 10, 25, 50]\n",
    "}\n",
    "\n",
    "ad = RandomForestRegressor(n_jobs=-1, oob_score=r2_score)\n",
    "\n",
    "for i in range(len(caracteristicas)):\n",
    "    x2 = x[caracteristicas[i]]\n",
    "\n",
    "    grid = RandomizedSearchCV(ad, parametros, n_iter=100, scoring='r2', n_jobs=-1)\n",
    "\n",
    "    grid.fit(x2, y)\n",
    "\n",
    "    print(f\"Mejores parámetros {modelos[i]}: {grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309f8fb3",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91de0af3",
   "metadata": {},
   "source": [
    "### Hipopotasemia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "80e6bc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Mejores parámetros AIC: {'n_estimators': 100, 'max_leaves': 50, 'max_depth': 50, 'learning_rate': 0.5}\n",
      " \n",
      "Mejores parámetros Boruta: {'n_estimators': 250, 'max_leaves': 25, 'max_depth': 25, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "parametros = {\n",
    "    'n_estimators': [100, 150, 200, 250],\n",
    "    'max_depth': [0, 10, 25, 50, 100],\n",
    "    'max_leaves': [0, 5, 10, 25, 50],\n",
    "    'learning_rate': [0.01, 0.1, 0.25, 0.5]\n",
    "}\n",
    "\n",
    "pesos = (len(y[y == 0]) / len(y[y==1]))\n",
    "\n",
    "ad = xgb.XGBClassifier(device=\"cuda\", n_jobs=-1, eval_metric=roc_auc_score, scale_pos_weight=pesos)\n",
    "\n",
    "for i in range(len(caracteristicas)):\n",
    "    x2 = x[caracteristicas[i]]\n",
    "\n",
    "    grid = RandomizedSearchCV(ad, parametros, n_iter=100, cv=skf, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "    grid.fit(cp.array(x2), y)\n",
    "\n",
    "    print(f' ')\n",
    "    print(f\"Mejores parámetros {modelos[i]}: {grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333d1ed1",
   "metadata": {},
   "source": [
    "### Hiperpotasemia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7a5dc735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Mejores parámetros AIC: {'n_estimators': 250, 'max_leaves': 0, 'max_depth': 25, 'learning_rate': 0.1}\n",
      " \n",
      "Mejores parámetros Boruta: {'n_estimators': 250, 'max_leaves': 0, 'max_depth': 50, 'learning_rate': 0.25}\n"
     ]
    }
   ],
   "source": [
    "parametros = {\n",
    "    'n_estimators': [100, 150, 200, 250],\n",
    "    'max_depth': [0, 10, 25, 50, 100],\n",
    "    'max_leaves': [0, 5, 10, 25, 50],\n",
    "    'learning_rate': [0.01, 0.1, 0.25, 0.5]\n",
    "}\n",
    "\n",
    "pesos = (len(y[y == 0]) / len(y[y==1]))\n",
    "\n",
    "ad = xgb.XGBClassifier(device=\"cuda\", n_jobs=-1, eval_metric=roc_auc_score, scale_pos_weight=pesos)\n",
    "\n",
    "for i in range(len(caracteristicas)):\n",
    "    x2 = x[caracteristicas[i]]\n",
    "\n",
    "    grid = RandomizedSearchCV(ad, parametros, n_iter=100, cv=skf, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "    grid.fit(cp.array(x2), y)\n",
    "\n",
    "    print(f' ')\n",
    "    print(f\"Mejores parámetros {modelos[i]}: {grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08edb51",
   "metadata": {},
   "source": [
    "### Regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "80688d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros AIC: {'n_estimators': 150, 'max_leaves': 10, 'max_depth': 25, 'learning_rate': 0.1}\n",
      "Mejores parámetros Boruta: {'n_estimators': 200, 'max_leaves': 0, 'max_depth': 10, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "parametros = {\n",
    "    'n_estimators': [100, 150, 200, 250],\n",
    "    'max_depth': [0, 10, 25, 50, 100],\n",
    "    'max_leaves': [0, 5, 10, 25, 50],\n",
    "    'learning_rate': [0.01, 0.1, 0.25, 0.5]\n",
    "}\n",
    "\n",
    "ad = xgb.XGBRegressor(device=\"cuda\", n_jobs=-1, eval_metric=r2_score)\n",
    "\n",
    "for i in range(len(caracteristicas)):\n",
    "    x2 = x[caracteristicas[i]]\n",
    "\n",
    "    grid = RandomizedSearchCV(ad, parametros, n_iter=100, scoring='r2', n_jobs=-1)\n",
    "\n",
    "    grid.fit(cp.array(x2), y)\n",
    "\n",
    "    print(f\"Mejores parámetros {modelos[i]}: {grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cf4101",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
