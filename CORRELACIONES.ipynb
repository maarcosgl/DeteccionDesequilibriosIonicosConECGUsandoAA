{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dba4c38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import de librerías necesarias\n",
    "import pyreadr\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Cursor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, date\n",
    "from sklearn import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "from scipy.stats import chi2\n",
    "from scipy.stats import chi2_contingency\n",
    "import scipy.stats as stats\n",
    "from sklearn.metrics import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.stats import mannwhitneyu\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from collections import defaultdict\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor \n",
    "from scipy.stats import spearmanr, kendalltau\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51e68ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar los datos de R a Python\n",
    "datos = pyreadr.read_r('area_desbalance_ionico.RData')\n",
    "\n",
    "#Para comprobar que se importan correctamente los datos\n",
    "#print(datos.keys())\n",
    "\n",
    "#Este archivo tiene tres variables\n",
    "\n",
    "#datos_anon_D: datos extraídos de los ECGS - edad, sexo, fecha, hora y \n",
    "#nombre del fichero. Hay un código (código) que identifica a cada paciente\n",
    "datos_anon_DF = datos['datos_anon_DF']\n",
    "\n",
    "#lead_anon_DF\n",
    "#variables electrocardiográficas correspondiente a los ECGs de la variable anterior\n",
    "leads_anon_DF = datos['leads_anon_DF']\n",
    "\n",
    "#pacs_con_ECGs_DF\n",
    "#variables de los datos del potasio, fecha de la analítica, edad del paciente, sexo\n",
    "#nivel de K y código del paciente\n",
    "pacs_con_ECGs_DF = datos['pacs_con_ECGs_DF']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dde6a01",
   "metadata": {},
   "source": [
    "# Normalidad - Hiperpotasemia - Hipopotasemia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "190d4314",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primer paso: coger solo los valores de K normales y de hiperpotasemia\n",
    "k_val = pacs_con_ECGs_DF.copy()\n",
    "\n",
    "limites = [float('-inf'), 3.5, 5.2, float('inf')]\n",
    "etiquetas = [1, 0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a819240",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_valores = k_val.copy()\n",
    "\n",
    "k_valores['categoria'] = pd.cut(k_valores['K'], bins=limites, labels=etiquetas, right=False)\n",
    "\n",
    "#Se reemplazan los sexos por enteros\n",
    "#1: Hombre\n",
    "#0: Mujer\n",
    "k_valores['Sexo'] = k_valores['Sexo'].replace({'M': 1, 'F': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb192f44",
   "metadata": {},
   "source": [
    "# Eliminación de variables con datos vacíos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5059f3d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#En leads_anon_DF, se van a eliminar aquellas columnas en las que falte más del 1% de los datos\n",
    "\n",
    "#El como máximo (el 100%) de datos que podría tener cada característica, sería igual al número total de filas que\n",
    "#hay registradas\n",
    "#Se calcula el 10% y se redondea sin decimales\n",
    "diez_pct_datos = round(len(leads_anon_DF) * 0.01, 0)\n",
    "\n",
    "#Ahora, se va a coger un subconjunto del dataframe en el que se eliminan las\n",
    "#características cuyo número de datos sea menor al 10%\n",
    "\n",
    "#Se cuenta el número de NaN o celdas sin datos en cada columna\n",
    "celdas_sin_datos = leads_anon_DF.isnull().sum()\n",
    "\n",
    "#Se cogen las características cuyo número de datos vacíos es mayor o igual al 10%\n",
    "caracteristicas_eliminar = celdas_sin_datos[celdas_sin_datos >= diez_pct_datos].index\n",
    "\n",
    "#Se crear el subDataFrame eliminando las columnas correspondientes\n",
    "leads_anon_DF_limpio = leads_anon_DF.drop(columns = caracteristicas_eliminar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e82f7dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora hay que asociar a cada análisis de sangre, su ECG más cercano\n",
    "def ECG_mas_reciente(fecha, codigo):\n",
    "     \n",
    "    archivos_ECGs = datos_anon_DF.loc[(datos_anon_DF['codigo'] == codigo) & (datos_anon_DF['date'] >= (fecha - timedelta(days=5))) & (datos_anon_DF['date'] <= (fecha + timedelta(days=5)))]    \n",
    "    \n",
    "    fechas_archivos = archivos_ECGs['date']\n",
    "    horas_archivos = archivos_ECGs['time']\n",
    "        \n",
    "    diferencia_temporal = [abs(fecha - fecha_archivo) for fecha_archivo in fechas_archivos]\n",
    "    \n",
    "    ecg = (datos_anon_DF.index[(datos_anon_DF['codigo'] == codigo) & (datos_anon_DF['date'] >= (fecha - timedelta(days=5))) & (datos_anon_DF['date'] <= (fecha + timedelta(days=5)))]).tolist()\n",
    "    \n",
    "    if(len(diferencia_temporal) > 0):\n",
    "    \n",
    "        combinado = list(zip(diferencia_temporal, ecg))\n",
    "        combinado = sorted(combinado, key=lambda x: x[0])\n",
    "\n",
    "        diferencia_temporal, ecg = zip(*combinado)\n",
    "        \n",
    "    return ecg, diferencia_temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8fba01f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Ahora, se añade la columna \"Categoria\" y \"Sexo\" a leads_anon_DF_limpio\n",
    "#Se crean esas columnas en el nuevo dataframe con valores a Nan\n",
    "leads_anon_DF_limpio['Sexo'] = float('NaN')\n",
    "leads_anon_DF_limpio['categoria'] = float('NaN')\n",
    "leads_anon_DF_limpio['K'] = float('NaN')\n",
    "leads_anon_DF_limpio['Edad'] = float('NaN')\n",
    "ecgs_utilizadas = {} \n",
    "\n",
    "for i in range(len(k_valores)):\n",
    "    fecha_hora = (k_valores['Fecha'].iloc[i]).to_pydatetime()\n",
    "    fecha = fecha_hora.date()\n",
    "    \n",
    "    indice, dist_temporal = ECG_mas_reciente(fecha, k_valores['codigo'].iloc[i])\n",
    "  \n",
    "    for j in range(len(indice)):\n",
    "        #Si el ECGs no tiene una analítica asignada, se le pone\n",
    "        if indice[j] not in ecgs_utilizadas:\n",
    "            #Se actualizan los valores de las columnas \"Sexo\" y \"Categoría\"\n",
    "            #de la fila correspondiente\n",
    "            leads_anon_DF_limpio.at[indice[j], 'Sexo'] = k_valores['Sexo'].iloc[i]\n",
    "            leads_anon_DF_limpio.at[indice[j], 'Edad'] = k_valores['Edad'].iloc[i]\n",
    "            leads_anon_DF_limpio.at[indice[j], 'categoria'] = k_valores['categoria'].iloc[i]\n",
    "            leads_anon_DF_limpio.at[indice[j], 'K'] = k_valores['K'].iloc[i]\n",
    "\n",
    "            ecgs_utilizadas[indice[j]] = [k_valores['categoria'].iloc[i], dist_temporal[j].days]\n",
    "\n",
    "        #Si el ECG ya tiene una analítica asociada, si la nueva analítica tiene un valor\n",
    "        #de categoría diferente y se asocia con una anormalidad, se cambia\n",
    "        else:\n",
    "            if((dist_temporal[j].days < ecgs_utilizadas[indice[j]][1])):\n",
    "                leads_anon_DF_limpio.at[indice[j], 'categoria'] = k_valores['categoria'].iloc[i]\n",
    "                leads_anon_DF_limpio.at[indice[j], 'K'] = k_valores['K'].iloc[i]\n",
    "                ecgs_utilizadas[indice[j]][1] = dist_temporal[j].days\n",
    "                \n",
    "            if((dist_temporal[j].days == ecgs_utilizadas[indice[j]][1]) & (k_valores['categoria'].iloc[i] > ecgs_utilizadas[indice[j]][0])):\n",
    "                leads_anon_DF_limpio.at[indice[j], 'categoria'] = k_valores['categoria'].iloc[i]\n",
    "                leads_anon_DF_limpio.at[indice[j], 'K'] = k_valores['K'].iloc[i]\n",
    "                ecgs_utilizadas[indice[j]][1] = dist_temporal[j].days                \n",
    "            \n",
    "#Se eliminan las filas que tengan la variable objetivo \"categoria\" a NaN\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.dropna(subset=['categoria'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e8f5237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analíticas normalidad: 1763\n",
      "Analíticas hipopotasemia: 260\n",
      "Analíticas hiperpotasemia: 750\n",
      "Analíticas normalidad: 1544\n",
      "Analíticas hipopotasemia: 189\n",
      "Analíticas hiperpotasemia: 750\n"
     ]
    }
   ],
   "source": [
    "print(f'Analíticas normalidad: {(k_valores[\"categoria\"] == 0).sum()}')\n",
    "print(f'Analíticas hipopotasemia: {(k_valores[\"categoria\"] == 1).sum()}')\n",
    "print(f'Analíticas hiperpotasemia: {(leads_anon_DF_limpio[\"categoria\"] == 2).sum()}')\n",
    "print(f'Analíticas normalidad: {(leads_anon_DF_limpio[\"categoria\"] == 0).sum()}')\n",
    "print(f'Analíticas hipopotasemia: {(leads_anon_DF_limpio[\"categoria\"] == 1).sum()}')\n",
    "print(f'Analíticas hiperpotasemia: {(leads_anon_DF_limpio[\"categoria\"] == 2).sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abb6f78",
   "metadata": {},
   "source": [
    "# Eliminación de características anormales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61da8eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pparea = leads_anon_DF_limpio.filter(regex='_pparea', axis=1)\n",
    "tparea = leads_anon_DF_limpio.filter(regex='_tparea', axis=1)\n",
    "\n",
    "ppamp = leads_anon_DF_limpio.filter(regex='_ppamp', axis=1)\n",
    "rpamp = leads_anon_DF_limpio.filter(regex='_rpamp', axis=1)\n",
    "spamp = leads_anon_DF_limpio.filter(regex='_spamp', axis=1)\n",
    "tpamp = leads_anon_DF_limpio.filter(regex='_tpamp', axis=1)\n",
    "\n",
    "rpdur = leads_anon_DF_limpio.filter(regex='_rpdur', axis=1)\n",
    "spdur = leads_anon_DF_limpio.filter(regex='_spdur', axis=1)\n",
    "tpdur = leads_anon_DF_limpio.filter(regex='_tpdur', axis=1)\n",
    "\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=pparea.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=tparea.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=ppamp.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=rpamp.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=spamp.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=tpamp.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=rpdur.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=spdur.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=tpdur.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd19f74",
   "metadata": {},
   "source": [
    "# Eliminación de correlaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b64209d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "parea = leads_anon_DF_limpio.filter(regex='_parea', axis=1)\n",
    "pppparea = leads_anon_DF_limpio.filter(regex='_pppparea', axis=1)\n",
    "qdur = leads_anon_DF_limpio.filter(regex='_qdur', axis=1)\n",
    "sdur = leads_anon_DF_limpio.filter(regex='_sdur', axis=1)\n",
    "tarea = leads_anon_DF_limpio.filter(regex='_tarea', axis=1)\n",
    "tptparea = leads_anon_DF_limpio.filter(regex='(_tptparea$)', axis=1)\n",
    "tptpdur = leads_anon_DF_limpio.filter(regex='(_tptpdur$)', axis=1)\n",
    "st = leads_anon_DF_limpio.filter(regex='(_stend$|_st80$|_ston$)', axis=1)\n",
    "stslope = leads_anon_DF_limpio.filter(regex='(_stslope)', axis=1)\n",
    "stdur = leads_anon_DF_limpio.filter(regex='(_stdur$)', axis=1).drop(columns=['V2_stdur'])\n",
    "\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=parea.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=pppparea.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=qdur.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=sdur.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=tarea.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=tptparea.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=tptpdur.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=st.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=stslope.columns)\n",
    "leads_anon_DF_limpio = leads_anon_DF_limpio.drop(columns=stdur.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b5d66c",
   "metadata": {},
   "source": [
    "# CARGA DE DATOS FINALIZADA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a794d7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53ac9e5",
   "metadata": {},
   "source": [
    "# Correlación entre variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a10add9",
   "metadata": {},
   "source": [
    "### Matriz de Correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b5d1c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_correlacion = leads_anon_DF_limpio.corr(method='spearman')\n",
    "\n",
    "#Se define un mínimo de correlación en valor absoluto del 0.7\n",
    "correlacion = 0.8\n",
    "\n",
    "#Se filtra la matrz\n",
    "filtro = (matriz_correlacion.abs() >= correlacion) & (matriz_correlacion.abs() < 1)\n",
    "\n",
    "car_colinealidad = matriz_correlacion.columns[filtro.any()]\n",
    "\n",
    "matriz_correlacion_filtrada = matriz_correlacion.loc[car_colinealidad, car_colinealidad]\n",
    "\n",
    "matriz_correlacion_filtrada = matriz_correlacion_filtrada.mask(matriz_correlacion_filtrada.abs() < correlacion)\n",
    "\n",
    "matriz_correlacion_filtrada.to_excel('matriz_corr.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea9cdc3",
   "metadata": {},
   "source": [
    "### VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "634be0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = leads_anon_DF_limpio.drop(['K', 'categoria'], axis = 1)\n",
    "x_2 = x_2.where(pd.notna(x_2), None)\n",
    "\n",
    "imputer = IterativeImputer(max_iter=5, sample_posterior=True, initial_strategy='mean', skip_complete=True)\n",
    "x_2 = pd.DataFrame(imputer.fit_transform(x_2), columns=x_2.columns)\n",
    "\n",
    "esc = StandardScaler()\n",
    "x_2 = pd.DataFrame(esc.fit_transform(x_2), columns=x_2.columns)\n",
    "\n",
    "VIF = pd.DataFrame()\n",
    "VIF['Caracteristica'] = x_2.columns\n",
    "VIF['VIF'] = [variance_inflation_factor(x_2.values, i) for i in range(len(x_2.columns))] \n",
    "VIF = VIF.sort_values('VIF', ascending=False)\n",
    "VIF.to_excel('VIF.xlsx', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f1d9e5",
   "metadata": {},
   "source": [
    "# Prueba Spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2405ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "II_parea - II_pamp: 0.9486530198606639, 0.0\n",
      "II_pppparea - II_pamp: 0.9302277853393132, 0.0\n",
      "II_qamp - II_qdur: -0.9672045125578507, 0.0\n",
      "II_samp - II_sdur: -0.9216391508002032, 0.0\n",
      "II_qrsdur - V5_qrsdur: 0.7793127754922046, 0.0\n",
      "II_ston - II_stmid: 0.9476840274250862, 0.0\n",
      "II_ston - II_st80: 0.8833209063108172, 0.0\n",
      "II_ston - II_stend: 0.8249256507917563, 0.0\n",
      "II_stmid - II_st80: 0.9534938319034615, 0.0\n",
      "II_stmid - II_stend: 0.9047735503148979, 0.0\n",
      "II_st80 - II_stend: 0.9451193701623133, 0.0\n",
      "II_stend - II_stslope: 0.6900601795793426, 0.0\n",
      "II_stdur - V3_stdur: 0.9899644011348282, 0.0\n",
      "II_tarea - II_tamp: 0.9717921814997652, 0.0\n",
      "II_tptparea - II_tamp: 0.963616737280656, 0.0\n",
      "II_tdur - II_tptpdur: 0.9080673014073167, 0.0\n",
      "II_qtint - V2_qtint: 0.7202490705405327, 0.0\n"
     ]
    }
   ],
   "source": [
    "cars = [\n",
    "    [\"II_parea\", \"II_pamp\"],\n",
    "    [\"II_pppparea\", \"II_pamp\"],\n",
    "    [\"II_qamp\", \"II_qdur\"],\n",
    "    [\"II_samp\", \"II_sdur\"],\n",
    "    [\"II_qrsdur\", \"V5_qrsdur\"],\n",
    "    [\"II_ston\", \"II_stmid\"],\n",
    "    [\"II_ston\", \"II_st80\"],\n",
    "    [\"II_ston\", \"II_stend\"],\n",
    "    [\"II_stmid\", \"II_st80\"],\n",
    "    [\"II_stmid\", \"II_stend\"],\n",
    "    [\"II_st80\", \"II_stend\"],\n",
    "    [\"II_stend\", \"II_stslope\"],\n",
    "    [\"II_stdur\", \"V3_stdur\"],\n",
    "    [\"II_tarea\", \"II_tamp\"],\n",
    "    [\"II_tptparea\", \"II_tamp\"],\n",
    "    [\"II_tdur\", \"II_tptpdur\"],\n",
    "    [\"II_qtint\", \"V2_qtint\"]\n",
    "]\n",
    "\n",
    "for i in range(len(cars)):\n",
    "    spearman_corr, spearman_p_value = spearmanr(leads_anon_DF_limpio[cars[i][0]].values, \n",
    "                                            leads_anon_DF_limpio[cars[i][1]].values, nan_policy='omit')\n",
    "    \n",
    "    print(f'{cars[i][0]} - {cars[i][1]}: {spearman_corr}, {spearman_p_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633964df",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
